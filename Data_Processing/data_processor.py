# Sui vs Aptos æ•¸æ“šè™•ç†å’Œæ¸…ç†å·¥å…·

import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
import os
import logging
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SuiAptosDataProcessor:
    """Sui vs Aptos æ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self, raw_data_dir="../Data_Collection/raw_data", output_dir="processed_data"):
        self.raw_data_dir = raw_data_dir
        self.output_dir = output_dir
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        for subdir in ['daily', 'weekly', 'monthly', 'analysis_ready']:
            os.makedirs(f"{output_dir}/{subdir}", exist_ok=True)
        
        logger.info(f"æ•¸æ“šè™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"åŸå§‹æ•¸æ“šç›®éŒ„: {raw_data_dir}")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    def load_raw_data(self):
        """è¼‰å…¥åŸå§‹æ•¸æ“š"""
        logger.info("é–‹å§‹è¼‰å…¥åŸå§‹æ•¸æ“š...")
        
        data = {}
        
        try:
            # è¼‰å…¥å”è­°æ•¸æ“š
            data['sui_protocols'] = pd.read_csv(f"{self.raw_data_dir}/sui_data/sui_protocols_final_20250822.csv")
            data['aptos_protocols'] = pd.read_csv(f"{self.raw_data_dir}/aptos_data/aptos_protocols_final_20250822.csv")
            
            # è¼‰å…¥åƒ¹æ ¼æ•¸æ“š
            data['sui_price'] = pd.read_csv(f"{self.raw_data_dir}/sui_data/sui_price_final_20250822.csv")
            data['aptos_price'] = pd.read_csv(f"{self.raw_data_dir}/aptos_data/aptos_price_final_20250822.csv")
            
            # è¼‰å…¥æ¯”è¼ƒåˆ†æ
            with open(f"{self.raw_data_dir}/comparison_data/sui_vs_aptos_final_20250822.json", 'r', encoding='utf-8') as f:
                data['comparison'] = json.load(f)
            
            logger.info("åŸå§‹æ•¸æ“šè¼‰å…¥æˆåŠŸ:")
            logger.info(f"  Suiå”è­°: {len(data['sui_protocols'])} å€‹")
            logger.info(f"  Aptoså”è­°: {len(data['aptos_protocols'])} å€‹")
            logger.info(f"  SUIåƒ¹æ ¼: {len(data['sui_price'])} å¤©")
            logger.info(f"  APTåƒ¹æ ¼: {len(data['aptos_price'])} å¤©")
            
            return data
            
        except Exception as e:
            logger.error(f"æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None
    
    def clean_protocol_data(self, protocols_df, chain_name):
        """æ¸…ç†å”è­°æ•¸æ“š"""
        logger.info(f"é–‹å§‹æ¸…ç† {chain_name} å”è­°æ•¸æ“š...")
        
        # è¤‡è£½æ•¸æ“šé¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
        df = protocols_df.copy()
        
        # 1. ç§»é™¤æ˜é¡¯çš„CEXå’ŒéDeFiå”è­°
        exclude_keywords = ['Binance', 'CEX', 'Exchange', 'OKX', 'Gate', 'Bybit', 'Coinbase', 'Kraken']
        exclude_pattern = '|'.join(exclude_keywords)
        
        initial_count = len(df)
        df = df[~df['name'].str.contains(exclude_pattern, case=False, na=False)]
        logger.info(f"  ç§»é™¤CEXå”è­°: {initial_count - len(df)} å€‹")
        
        # 2. è™•ç†TVLç•°å¸¸å€¼
        # ç§»é™¤TVLç‚º0æˆ–è² æ•¸çš„å”è­°
        df = df[df['tvl_usd'] > 0]
        
        # æ¨™è¨˜TVLç•°å¸¸é«˜çš„å”è­° (å¯èƒ½æ˜¯æ•¸æ“šéŒ¯èª¤)
        tvl_q99 = df['tvl_usd'].quantile(0.99)
        df['is_outlier'] = df['tvl_usd'] > tvl_q99
        logger.info(f"  æ¨™è¨˜TVLç•°å¸¸å€¼: {df['is_outlier'].sum()} å€‹ (>99åˆ†ä½æ•¸: ${tvl_q99:,.0f})")
        
        # 3. åˆ†é¡æ¨™æº–åŒ–
        category_mapping = {
            'Dexes': 'DEX',
            'Derivatives': 'Derivatives', 
            'Lending': 'Lending',
            'Yield': 'Yield Farming',
            'Liquid Staking': 'Liquid Staking',
            'Bridge': 'Bridge',
            'Launchpad': 'Launchpad',
            'Gaming': 'Gaming',
            'NFT': 'NFT',
            'Insurance': 'Insurance',
            'Unknown': 'Others'
        }
        
        df['category_clean'] = df['category'].map(category_mapping).fillna('Others')
        
        # 4. æ·»åŠ è¨ˆç®—æ¬„ä½
        df['tvl_millions'] = df['tvl_usd'] / 1_000_000
        df['tvl_billions'] = df['tvl_usd'] / 1_000_000_000
        
        # 5. è¨ˆç®—å¢é•·è©•åˆ† (åŸºæ–¼è®ŠåŒ–ç‡)
        df['growth_score'] = (
            df['change_7d'].fillna(0) * 0.5 + 
            df['change_1m'].fillna(0) * 0.3 + 
            df['change_1d'].fillna(0) * 0.2
        )
        
        # 6. æ·»åŠ æ’å
        df['tvl_rank'] = df['tvl_usd'].rank(method='dense', ascending=False)
        df['growth_rank'] = df['growth_score'].rank(method='dense', ascending=False)
        
        logger.info(f"  {chain_name} æ¸…ç†å®Œæˆ: {len(df)} å€‹æœ‰æ•ˆå”è­°")
        
        return df
    
    def clean_price_data(self, price_df, chain_name):
        """æ¸…ç†åƒ¹æ ¼æ•¸æ“š"""
        logger.info(f"é–‹å§‹æ¸…ç† {chain_name} åƒ¹æ ¼æ•¸æ“š...")
        
        df = price_df.copy()
        
        # 1. è½‰æ›æ—¥æœŸæ ¼å¼
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        # 2. è™•ç†ç¼ºå¤±å€¼
        numeric_cols = ['price_usd', 'market_cap_usd', 'volume_24h_usd']
        for col in numeric_cols:
            if col in df.columns:
                # ä½¿ç”¨å‰å€¼å¡«å……å°é‡ç¼ºå¤±å€¼
                df[col] = df[col].fillna(method='ffill')
        
        # 3. è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        df['price_change_1d'] = df['price_usd'].pct_change()
        df['price_change_7d'] = df['price_usd'].pct_change(periods=7)
        df['price_change_30d'] = df['price_usd'].pct_change(periods=30)
        
        # 4. ç§»å‹•å¹³å‡
        df['ma_7d'] = df['price_usd'].rolling(window=7).mean()
        df['ma_30d'] = df['price_usd'].rolling(window=30).mean()
        
        # 5. æ³¢å‹•ç‡ (30å¤©æ»¾å‹•æ¨™æº–å·®)
        df['volatility_30d'] = df['price_change_1d'].rolling(window=30).std()
        
        # 6. ç´¯ç©å›å ±
        df['cumulative_return'] = (df['price_usd'] / df['price_usd'].iloc[0] - 1) * 100
        
        # 7. æ·»åŠ æ™‚é–“ç‰¹å¾µ
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['quarter'] = df['date'].dt.quarter
        df['weekday'] = df['date'].dt.dayofweek
        
        logger.info(f"  {chain_name} åƒ¹æ ¼æ•¸æ“šæ¸…ç†å®Œæˆ: {len(df)} å¤©")
        
        return df
    
    def create_comparative_analysis(self, sui_protocols_clean, aptos_protocols_clean, sui_price_clean, aptos_price_clean):
        """å‰µå»ºæ¯”è¼ƒåˆ†ææ•¸æ“šé›†"""
        logger.info("é–‹å§‹å‰µå»ºæ¯”è¼ƒåˆ†ææ•¸æ“šé›†...")
        
        analysis = {}
        
        # 1. å”è­°æ¯”è¼ƒ
        protocol_comparison = {
            'category_comparison': self._compare_categories(sui_protocols_clean, aptos_protocols_clean),
            'size_distribution': self._analyze_size_distribution(sui_protocols_clean, aptos_protocols_clean),
            'growth_comparison': self._compare_growth_metrics(sui_protocols_clean, aptos_protocols_clean),
            'concentration_analysis': self._analyze_concentration(sui_protocols_clean, aptos_protocols_clean)
        }
        
        # 2. åƒ¹æ ¼æ¯”è¼ƒ
        price_comparison = {
            'performance_metrics': self._compare_price_performance(sui_price_clean, aptos_price_clean),
            'risk_metrics': self._compare_risk_metrics(sui_price_clean, aptos_price_clean),
            'correlation_analysis': self._analyze_price_correlation(sui_price_clean, aptos_price_clean)
        }
        
        # 3. ç¶œåˆè©•åˆ†
        ecosystem_scores = self._calculate_ecosystem_scores(
            sui_protocols_clean, aptos_protocols_clean, 
            sui_price_clean, aptos_price_clean
        )
        
        analysis = {
            'protocol_comparison': protocol_comparison,
            'price_comparison': price_comparison,
            'ecosystem_scores': ecosystem_scores,
            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return analysis
    
    def _compare_categories(self, sui_df, aptos_df):
        """æ¯”è¼ƒå”è­°åˆ†é¡åˆ†ä½ˆ"""
        sui_categories = sui_df.groupby('category_clean').agg({
            'tvl_usd': ['sum', 'count', 'mean']
        }).round(0)
        
        aptos_categories = aptos_df.groupby('category_clean').agg({
            'tvl_usd': ['sum', 'count', 'mean']
        }).round(0)
        
        # è½‰æ›ç‚ºç°¡å–®å­—å…¸æ ¼å¼
        sui_cat_dict = {}
        aptos_cat_dict = {}
        
        for category in sui_categories.index:
            sui_cat_dict[category] = {
                'total_tvl': float(sui_categories.loc[category, ('tvl_usd', 'sum')]),
                'protocol_count': int(sui_categories.loc[category, ('tvl_usd', 'count')]),
                'avg_tvl': float(sui_categories.loc[category, ('tvl_usd', 'mean')])
            }
        
        for category in aptos_categories.index:
            aptos_cat_dict[category] = {
                'total_tvl': float(aptos_categories.loc[category, ('tvl_usd', 'sum')]),
                'protocol_count': int(aptos_categories.loc[category, ('tvl_usd', 'count')]),
                'avg_tvl': float(aptos_categories.loc[category, ('tvl_usd', 'mean')])
            }
        
        return {
            'sui_categories': sui_cat_dict,
            'aptos_categories': aptos_cat_dict
        }
    
    def _analyze_size_distribution(self, sui_df, aptos_df):
        """åˆ†æå”è­°è¦æ¨¡åˆ†ä½ˆ"""
        size_brackets = [0, 1e6, 10e6, 100e6, 1e9, float('inf')]
        size_labels = ['<$1M', '$1M-$10M', '$10M-$100M', '$100M-$1B', '>$1B']
        
        sui_df['size_bracket'] = pd.cut(sui_df['tvl_usd'], bins=size_brackets, labels=size_labels)
        aptos_df['size_bracket'] = pd.cut(aptos_df['tvl_usd'], bins=size_brackets, labels=size_labels)
        
        sui_dist = sui_df['size_bracket'].value_counts().to_dict()
        aptos_dist = aptos_df['size_bracket'].value_counts().to_dict()
        
        return {
            'sui_distribution': {str(k): int(v) for k, v in sui_dist.items()},
            'aptos_distribution': {str(k): int(v) for k, v in aptos_dist.items()}
        }
    
    def _compare_growth_metrics(self, sui_df, aptos_df):
        """æ¯”è¼ƒå¢é•·æŒ‡æ¨™"""
        return {
            'sui_growth': {
                'avg_7d_change': float(sui_df['change_7d'].mean()),
                'avg_30d_change': float(sui_df['change_1m'].mean()),
                'positive_growth_7d': int((sui_df['change_7d'] > 0).sum()),
                'negative_growth_7d': int((sui_df['change_7d'] < 0).sum())
            },
            'aptos_growth': {
                'avg_7d_change': float(aptos_df['change_7d'].mean()),
                'avg_30d_change': float(aptos_df['change_1m'].mean()),
                'positive_growth_7d': int((aptos_df['change_7d'] > 0).sum()),
                'negative_growth_7d': int((aptos_df['change_7d'] < 0).sum())
            }
        }
    
    def _analyze_concentration(self, sui_df, aptos_df):
        """åˆ†æç”Ÿæ…‹é›†ä¸­åº¦"""
        sui_total = sui_df['tvl_usd'].sum()
        aptos_total = aptos_df['tvl_usd'].sum()
        
        return {
            'sui_concentration': {
                'top_1_share': float(sui_df.iloc[0]['tvl_usd'] / sui_total * 100),
                'top_5_share': float(sui_df.head(5)['tvl_usd'].sum() / sui_total * 100),
                'top_10_share': float(sui_df.head(10)['tvl_usd'].sum() / sui_total * 100),
                'herfindahl_index': float((sui_df['tvl_usd'] / sui_total).pow(2).sum())
            },
            'aptos_concentration': {
                'top_1_share': float(aptos_df.iloc[0]['tvl_usd'] / aptos_total * 100),
                'top_5_share': float(aptos_df.head(5)['tvl_usd'].sum() / aptos_total * 100),
                'top_10_share': float(aptos_df.head(10)['tvl_usd'].sum() / aptos_total * 100),
                'herfindahl_index': float((aptos_df['tvl_usd'] / aptos_total).pow(2).sum())
            }
        }
    
    def _compare_price_performance(self, sui_price, aptos_price):
        """æ¯”è¼ƒåƒ¹æ ¼è¡¨ç¾"""
        periods = [7, 30, 90, 180]
        performance = {}
        
        for period in periods:
            if len(sui_price) > period and len(aptos_price) > period:
                sui_return = ((sui_price.iloc[-1]['price_usd'] - sui_price.iloc[-period]['price_usd']) 
                             / sui_price.iloc[-period]['price_usd'] * 100)
                aptos_return = ((aptos_price.iloc[-1]['price_usd'] - aptos_price.iloc[-period]['price_usd']) 
                               / aptos_price.iloc[-period]['price_usd'] * 100)
                
                performance[f'{period}_days'] = {
                    'sui_return': float(sui_return),
                    'aptos_return': float(aptos_return),
                    'outperformance': float(sui_return - aptos_return)
                }
        
        return performance
    
    def _compare_risk_metrics(self, sui_price, aptos_price):
        """æ¯”è¼ƒé¢¨éšªæŒ‡æ¨™"""
        return {
            'volatility_30d': {
                'sui': float(sui_price['volatility_30d'].iloc[-1]),
                'aptos': float(aptos_price['volatility_30d'].iloc[-1])
            },
            'max_drawdown': {
                'sui': float((sui_price['price_usd'].cummax() - sui_price['price_usd']).max() / sui_price['price_usd'].cummax().max() * 100),
                'aptos': float((aptos_price['price_usd'].cummax() - aptos_price['price_usd']).max() / aptos_price['price_usd'].cummax().max() * 100)
            }
        }
    
    def _analyze_price_correlation(self, sui_price, aptos_price):
        """åˆ†æåƒ¹æ ¼ç›¸é—œæ€§"""
        # åˆä½µæ•¸æ“šä»¥è¨ˆç®—ç›¸é—œæ€§
        merged = pd.merge(sui_price[['date', 'price_change_1d']], 
                         aptos_price[['date', 'price_change_1d']], 
                         on='date', suffixes=('_sui', '_aptos'))
        
        correlation = merged['price_change_1d_sui'].corr(merged['price_change_1d_aptos'])
        
        return {
            'daily_correlation': float(correlation),
            'correlation_strength': 'High' if abs(correlation) > 0.7 else 'Medium' if abs(correlation) > 0.4 else 'Low'
        }
    
    def _calculate_ecosystem_scores(self, sui_protocols, aptos_protocols, sui_price, aptos_price):
        """è¨ˆç®—ç”Ÿæ…‹ç³»çµ±ç¶œåˆè©•åˆ†"""
        
        # TVLè©•åˆ† (Aptos = 100, Suiç›¸å°è©•åˆ†)
        sui_tvl = sui_protocols['tvl_usd'].sum()
        aptos_tvl = aptos_protocols['tvl_usd'].sum()
        tvl_score_sui = (sui_tvl / aptos_tvl) * 100
        tvl_score_aptos = 100
        
        # å¤šæ¨£æ€§è©•åˆ† (å”è­°æ•¸é‡)
        diversity_score_sui = len(sui_protocols)
        diversity_score_aptos = len(aptos_protocols)
        
        # å¢é•·è©•åˆ† (åŸºæ–¼90å¤©åƒ¹æ ¼è¡¨ç¾)
        sui_90d_return = ((sui_price.iloc[-1]['price_usd'] - sui_price.iloc[-91]['price_usd']) 
                         / sui_price.iloc[-91]['price_usd'] * 100) if len(sui_price) > 90 else 0
        aptos_90d_return = ((aptos_price.iloc[-1]['price_usd'] - aptos_price.iloc[-91]['price_usd']) 
                           / aptos_price.iloc[-91]['price_usd'] * 100) if len(aptos_price) > 90 else 0
        
        # æ¨™æº–åŒ–è©•åˆ† (0-100)
        growth_score_sui = max(0, min(100, 50 + sui_90d_return))
        growth_score_aptos = max(0, min(100, 50 + aptos_90d_return))
        
        # ç¶œåˆè©•åˆ†
        sui_overall = (tvl_score_sui * 0.4 + diversity_score_sui * 0.3 + growth_score_sui * 0.3)
        aptos_overall = (tvl_score_aptos * 0.4 + diversity_score_aptos * 0.3 + growth_score_aptos * 0.3)
        
        return {
            'sui_scores': {
                'tvl_score': float(tvl_score_sui),
                'diversity_score': float(diversity_score_sui),
                'growth_score': float(growth_score_sui),
                'overall_score': float(sui_overall)
            },
            'aptos_scores': {
                'tvl_score': float(tvl_score_aptos),
                'diversity_score': float(diversity_score_aptos),
                'growth_score': float(growth_score_aptos),
                'overall_score': float(aptos_overall)
            }
        }
    
    def save_processed_data(self, processed_data):
        """ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š"""
        logger.info("é–‹å§‹ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š...")
        
        timestamp = datetime.now().strftime('%Y%m%d')
        
        # ä¿å­˜æ¸…ç†å¾Œçš„æ•¸æ“š
        processed_data['sui_protocols_clean'].to_csv(
            f"{self.output_dir}/daily/sui_protocols_clean_{timestamp}.csv", index=False)
        
        processed_data['aptos_protocols_clean'].to_csv(
            f"{self.output_dir}/daily/aptos_protocols_clean_{timestamp}.csv", index=False)
        
        processed_data['sui_price_clean'].to_csv(
            f"{self.output_dir}/daily/sui_price_clean_{timestamp}.csv", index=False)
        
        processed_data['aptos_price_clean'].to_csv(
            f"{self.output_dir}/daily/aptos_price_clean_{timestamp}.csv", index=False)
        
        # ä¿å­˜æ¯”è¼ƒåˆ†æ
        with open(f"{self.output_dir}/analysis_ready/comparative_analysis_{timestamp}.json", 'w', encoding='utf-8') as f:
            json.dump(processed_data['comparative_analysis'], f, ensure_ascii=False, indent=2)
        
        logger.info("è™•ç†å¾Œæ•¸æ“šä¿å­˜å®Œæˆ")
    
    def process_all_data(self):
        """åŸ·è¡Œå®Œæ•´çš„æ•¸æ“šè™•ç†æµç¨‹"""
        logger.info("=== é–‹å§‹æ•¸æ“šè™•ç†æµç¨‹ ===")
        
        # 1. è¼‰å…¥åŸå§‹æ•¸æ“š
        raw_data = self.load_raw_data()
        if raw_data is None:
            logger.error("åŸå§‹æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œçµ‚æ­¢è™•ç†")
            return None
        
        # 2. æ¸…ç†å”è­°æ•¸æ“š
        sui_protocols_clean = self.clean_protocol_data(raw_data['sui_protocols'], 'Sui')
        aptos_protocols_clean = self.clean_protocol_data(raw_data['aptos_protocols'], 'Aptos')
        
        # 3. æ¸…ç†åƒ¹æ ¼æ•¸æ“š
        sui_price_clean = self.clean_price_data(raw_data['sui_price'], 'Sui')
        aptos_price_clean = self.clean_price_data(raw_data['aptos_price'], 'Aptos')
        
        # 4. å‰µå»ºæ¯”è¼ƒåˆ†æ
        comparative_analysis = self.create_comparative_analysis(
            sui_protocols_clean, aptos_protocols_clean,
            sui_price_clean, aptos_price_clean
        )
        
        # 5. æ•´åˆè™•ç†å¾Œæ•¸æ“š
        processed_data = {
            'sui_protocols_clean': sui_protocols_clean,
            'aptos_protocols_clean': aptos_protocols_clean,
            'sui_price_clean': sui_price_clean,
            'aptos_price_clean': aptos_price_clean,
            'comparative_analysis': comparative_analysis
        }
        
        # 6. ä¿å­˜è™•ç†å¾Œæ•¸æ“š
        self.save_processed_data(processed_data)
        
        logger.info("=== æ•¸æ“šè™•ç†æµç¨‹å®Œæˆ ===")
        return processed_data

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("ğŸ”§ Sui vs Aptos æ•¸æ“šè™•ç†å·¥å…·")
    print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 50)
    
    # å‰µå»ºæ•¸æ“šè™•ç†å™¨
    processor = SuiAptosDataProcessor()
    
    try:
        # åŸ·è¡Œæ•¸æ“šè™•ç†
        processed_data = processor.process_all_data()
        
        if processed_data:
            print("\nğŸ“Š æ•¸æ“šè™•ç†æ‘˜è¦:")
            print("=" * 40)
            
            # é¡¯ç¤ºæ¸…ç†å¾Œçš„æ•¸æ“šçµ±è¨ˆ
            print(f"âœ… Suiå”è­° (æ¸…ç†å¾Œ): {len(processed_data['sui_protocols_clean'])} å€‹")
            print(f"âœ… Aptoså”è­° (æ¸…ç†å¾Œ): {len(processed_data['aptos_protocols_clean'])} å€‹")
            print(f"âœ… SUIåƒ¹æ ¼æ•¸æ“š: {len(processed_data['sui_price_clean'])} å¤©")
            print(f"âœ… APTåƒ¹æ ¼æ•¸æ“š: {len(processed_data['aptos_price_clean'])} å¤©")
            
            # é¡¯ç¤ºä¸€äº›é—œéµæ´å¯Ÿ
            comp_analysis = processed_data['comparative_analysis']
            if 'ecosystem_scores' in comp_analysis:
                scores = comp_analysis['ecosystem_scores']
                print(f"\nğŸ† ç”Ÿæ…‹ç³»çµ±è©•åˆ†:")
                print(f"  Sui ç¶œåˆè©•åˆ†: {scores['sui_scores']['overall_score']:.1f}")
                print(f"  Aptos ç¶œåˆè©•åˆ†: {scores['aptos_scores']['overall_score']:.1f}")
            
            print(f"\nğŸ“ è™•ç†å¾Œæ•¸æ“šä¿å­˜ä½ç½®: {processor.output_dir}/")
            print(f"ğŸ• å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            return 0
        else:
            print("âŒ æ•¸æ“šè™•ç†å¤±æ•—")
            return 1
            
    except Exception as e:
        logger.error(f"æ•¸æ“šè™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)